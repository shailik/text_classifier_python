{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\naras\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\naras\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importing all the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import words\n",
    "nltk.download('stopwords')\n",
    "# ML Libraries\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to read train file\n",
    "\n",
    "def load_dataset_train(filename):\n",
    "    dataset_train = pd.read_csv(filename)\n",
    "    return dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to read test file\n",
    "\n",
    "def load_dataset_test(filename):\n",
    "    dataset_test = pd.read_csv(filename)\n",
    "    return dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to remove unwanted columns from train dataset\n",
    "\n",
    "def remove_unwanted_cols_train(dataset_train, cols):\n",
    "    for col in cols:\n",
    "        del dataset_train[col]\n",
    "    return dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to remove unwanted columns from test dataset\n",
    "\n",
    "def remove_unwanted_cols_test(dataset_test, cols):\n",
    "    for col in cols:\n",
    "        del dataset_test[col]\n",
    "    return dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to clean the tweets\n",
    "\n",
    "def preprocess_tweet_text(tweet):\n",
    "    tweet.lower()\n",
    "    \n",
    "    # Remove urls\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove user @ references and '#' from tweet\n",
    "    tweet = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(RT)\", \" \", tweet)\n",
    "    \n",
    "    # Remove punctuations\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    tweet_tokens = word_tokenize(tweet)\n",
    "    filtered_words = [w for w in tweet_tokens if not w in stop]\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    stemmed_words = [ps.stem(w) for w in filtered_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words = [lemmatizer.lemmatize(w, pos='a') for w in stemmed_words]\n",
    "    \n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to implement vectorization (convert text to numbers) using tf-idf technique\n",
    "\n",
    "def get_feature_vector(train_fit):\n",
    "    vector = TfidfVectorizer(sublinear_tf=True)\n",
    "    vector.fit(train_fit)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling all the function\n",
    "\n",
    "#load train dataset\n",
    "dataset_train = load_dataset_train(\"train.csv\")\n",
    "\n",
    "#Load test dataset\n",
    "dataset_test = load_dataset_test(\"test.csv\")\n",
    "\n",
    "# Remove unwanted columns from train dataset\n",
    "n_dataset_train = remove_unwanted_cols_train(dataset_train, ['screen_name','tweet_id','tweet_source','retweet_count'])\n",
    "\n",
    "# Remove unwanted columns from test dataset\n",
    "n_dataset_test = remove_unwanted_cols_test(dataset_test, ['screen_name','tweet_id','tweet_source','retweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y'all just mad because ya'll got caught trying...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @adams2011: #Retweet\\nI WILL VOTE AGAINST T...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @gomee_art: for sakusa it was love at first...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @gomee_art: for sakusa it was love at first...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@brithume @realDonaldTrump Yeah, look at that....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text Sentiment\n",
       "0  Y'all just mad because ya'll got caught trying...  Negative\n",
       "1  RT @adams2011: #Retweet\\nI WILL VOTE AGAINST T...   Neutral\n",
       "2  RT @gomee_art: for sakusa it was love at first...  Positive\n",
       "3  RT @gomee_art: for sakusa it was love at first...  Positive\n",
       "4  @brithume @realDonaldTrump Yeah, look at that....  Positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess train data\n",
    "dataset_train['tweet_text'] = dataset_train['tweet_text'].apply(str)\n",
    "dataset_train['tweet_text'] = dataset_train['tweet_text'].apply(preprocess_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test data\n",
    "dataset_test['tweet_text'] = dataset_test['tweet_text'].apply(str)\n",
    "dataset_test['tweet_text'] = dataset_test['tweet_text'].apply(preprocess_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y mad ya got caught trying party ignored Socia...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah look Somebody right thing Oh funny How ma...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text Sentiment\n",
       "0  Y mad ya got caught trying party ignored Socia...  Negative\n",
       "1  Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...   Neutral\n",
       "2   art sakusa love first disinfectant spray haikyuu  Positive\n",
       "3   art sakusa love first disinfectant spray haikyuu  Positive\n",
       "4  Yeah look Somebody right thing Oh funny How ma...  Positive"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These niggas scammers amp drug dealers NOTHING...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Mr President China already discovered vac...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whippits A NASTY DRUG Do Not get shit never th...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amy Klobuchar admitted Hydroxychloroquine save...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amy Klobuchar admitted Hydroxychloroquine save...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text Sentiment\n",
       "0  These niggas scammers amp drug dealers NOTHING...   Neutral\n",
       "1  Dear Mr President China already discovered vac...   Neutral\n",
       "2  Whippits A NASTY DRUG Do Not get shit never th...  Negative\n",
       "3  Amy Klobuchar admitted Hydroxychloroquine save...   Neutral\n",
       "4  Amy Klobuchar admitted Hydroxychloroquine save...   Neutral"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into Train, Test\n",
    "\n",
    "# Same tf vector will be used for Testing sentiments on unseen trending data\n",
    "tf_vector = get_feature_vector(np.array(dataset_train.iloc[:, 0]).ravel())\n",
    "X = tf_vector.transform(np.array(dataset_train.iloc[:, 0]).ravel())\n",
    "y = np.array(dataset_train.iloc[:, 1]).ravel()\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test = tf_vector.transform(np.array(dataset_test.iloc[:, 0]).ravel())\n",
    "y_test = np.array(dataset_test.iloc[:, 1]).ravel()\n",
    "\n",
    "#train_test_split(X, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Neutral', 'Positive', ..., 'Negative', 'Neutral',\n",
       "       'Neutral'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55869\n"
     ]
    }
   ],
   "source": [
    "# Training Naive Bayes model\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "y_predict_nb = NB_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predict_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naras\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Training Logistics Regression model\n",
    "LR_model = LogisticRegression(solver='lbfgs')\n",
    "LR_model.fit(X_train, y_train)\n",
    "y_predict_lr = LR_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predict_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training SVM model\n",
    "from sklearn import svm\n",
    "SVM_model = svm.SVC(kernel='linear',C=0.025,random_state=101)\n",
    "SVM_model.fit(X_train, y_train)\n",
    "y_predict_svm = svm_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predict_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing logistic regression model on test data\n",
    "\n",
    "test_file_name = \"test.csv\"\n",
    "test_ds = load_dataset_test(test_file_name)\n",
    "test_ds = remove_unwanted_cols_test(test_ds, ['screen_name','tweet_id','tweet_source','retweet_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y'all just mad because ya'll got caught trying...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @adams2011: #Retweet\\nI WILL VOTE AGAINST T...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @gomee_art: for sakusa it was love at first...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @gomee_art: for sakusa it was love at first...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@brithume @realDonaldTrump Yeah, look at that....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text Sentiment\n",
       "0  Y'all just mad because ya'll got caught trying...  Negative\n",
       "1  RT @adams2011: #Retweet\\nI WILL VOTE AGAINST T...   Neutral\n",
       "2  RT @gomee_art: for sakusa it was love at first...  Positive\n",
       "3  RT @gomee_art: for sakusa it was love at first...  Positive\n",
       "4  @brithume @realDonaldTrump Yeah, look at that....  Positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63186\n"
     ]
    }
   ],
   "source": [
    "# Using Logistic Regression model for prediction on test data\n",
    "\n",
    "test_prediction_lr = LR_model.predict(X_test)\n",
    "print(accuracy_score(y_test, test_prediction_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y mad ya got caught trying party ignored Socia...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah look Somebody right thing Oh funny How ma...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TrumpIsAnIdiot midnightmitch</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7 Within 3 years Trump caused much greater dam...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>heidi I watched deliver closing I feel sick di...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q How many citizens Trump willing 2 let die 2 ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TrumpGolfsYouDie TrumpHasNoPlan TrumpDeathToll...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Well anyone family served</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>On Memorial Day let remember Trump fired Cozie...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MAGAMorons maga TrumpIsAnIdiot MAGAts</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Having SmallBusiness living Red community I ne...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What happened TrumpIsALaughingStock realDonald...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The Trump Train bus South Carolina showed Hava...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Root WhiteNationalism wherever may hiding Raci...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Attacking veteran Memorial Day You sunk new lo...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Given Trump said U S cases would go 15 0 hawke...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>jay Right We get medical advice someone looks ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Good Morning Beautiful Ones Happy Sunday Deplo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Let party I follow back resisters TrumpHasNoPl...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Yuuuuuup unmanly TrumpIsAnIdiot</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>No bluffing By cleaning disinfecting frequentl...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>COVID 19 TrumpHasNoPlan TrumpIsALoser TrumpLie...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td></td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>WTH I think needs medic No wait give disinfect...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>heidi I watched deliver closing I feel sick di...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Yikes TrumpGolfsYouDie TrumpHasNoPlan TrumpDea...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Sexagenarian Nashik man innovative disinfectan...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>No running NOT choice need TakeUSABack becomin...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>art sakusa love first disinfectant spray haikyuu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_text prediction\n",
       "0   Y mad ya got caught trying party ignored Socia...   Negative\n",
       "1   Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...    Neutral\n",
       "2    art sakusa love first disinfectant spray haikyuu   Positive\n",
       "3    art sakusa love first disinfectant spray haikyuu   Positive\n",
       "4   Yeah look Somebody right thing Oh funny How ma...   Positive\n",
       "5    art sakusa love first disinfectant spray haikyuu   Positive\n",
       "6                        TrumpIsAnIdiot midnightmitch    Neutral\n",
       "7   Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...    Neutral\n",
       "8   7 Within 3 years Trump caused much greater dam...    Neutral\n",
       "9    art sakusa love first disinfectant spray haikyuu   Positive\n",
       "10  Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...    Neutral\n",
       "11  heidi I watched deliver closing I feel sick di...   Negative\n",
       "12  Q How many citizens Trump willing 2 let die 2 ...   Positive\n",
       "13  TrumpGolfsYouDie TrumpHasNoPlan TrumpDeathToll...    Neutral\n",
       "14                          Well anyone family served    Neutral\n",
       "15   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "16  Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...    Neutral\n",
       "17  On Memorial Day let remember Trump fired Cozie...    Neutral\n",
       "18              MAGAMorons maga TrumpIsAnIdiot MAGAts    Neutral\n",
       "19  Having SmallBusiness living Red community I ne...    Neutral\n",
       "20  What happened TrumpIsALaughingStock realDonald...    Neutral\n",
       "21   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "22  The Trump Train bus South Carolina showed Hava...    Neutral\n",
       "23  Root WhiteNationalism wherever may hiding Raci...    Neutral\n",
       "24   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "25   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "26  Attacking veteran Memorial Day You sunk new lo...    Neutral\n",
       "27  Given Trump said U S cases would go 15 0 hawke...    Neutral\n",
       "28  jay Right We get medical advice someone looks ...   Positive\n",
       "29  Good Morning Beautiful Ones Happy Sunday Deplo...   Positive\n",
       "30   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "31  Let party I follow back resisters TrumpHasNoPl...    Neutral\n",
       "32                    Yuuuuuup unmanly TrumpIsAnIdiot    Neutral\n",
       "33   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "34   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "35  No bluffing By cleaning disinfecting frequentl...    Neutral\n",
       "36  COVID 19 TrumpHasNoPlan TrumpIsALoser TrumpLie...    Neutral\n",
       "37                                                       Neutral\n",
       "38   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "39   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "40   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "41  WTH I think needs medic No wait give disinfect...    Neutral\n",
       "42  heidi I watched deliver closing I feel sick di...   Negative\n",
       "43  Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...    Neutral\n",
       "44  Retweet I WILL VOTE AGAINST TRUMP EVEN IN MY L...    Neutral\n",
       "45  Yikes TrumpGolfsYouDie TrumpHasNoPlan TrumpDea...    Neutral\n",
       "46  Sexagenarian Nashik man innovative disinfectan...   Positive\n",
       "47  No running NOT choice need TakeUSABack becomin...    Neutral\n",
       "48   art sakusa love first disinfectant spray haikyuu   Positive\n",
       "49   art sakusa love first disinfectant spray haikyuu   Positive"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print test data\n",
    "data_tweet = dataset_test['tweet_text']\n",
    "test_result_ds = pd.DataFrame({'tweet_text': data_tweet, 'prediction':test_prediction_lr})\n",
    "test_result_ds.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
